## Inbound Flow
1. **Secure prompt transmission and context gathering**
    Copilot collects context details:
        -  Code before and after the cursor position, which helps it understand the immediate context of the prompt.
        - Filename and type of the file being edited, allowing it to tailor code suggestions to the specific file type.
        - Information about adjacent open tabs, ensuring that the generated code aligns with other code segments in the same project.
        - Information on project structure and file paths
        - Information on programming languages and frameworks
        - Pre-processing using [Fill-in-the-Middle](https://medium.com/@SymeCloud/what-is-fim-and-why-does-it-matter-in-llm-based-ai-53f33385585b) (FIM) technique to consider both the preceding and following code context, effectively expanding the model's understanding allowing Copilot to generate more accurate and relevant code suggestions by leveraging a broader context.
2. **Proxy filter**
    The proxy filters traffic, blocking attempts to hack the prompt or manipulate the system into revealing details about how the model generates code suggestions.
3. **Toxicity filtering**
    - **Hate speech and inappropriate content**: Copilot employs algorithms to detect and prevent the intake of hate speech, offensive language, or inappropriate content that could be harmful or offensive.
    - **Personal data**: Copilot actively filters out any personal data, such as names, addresses, or identification numbers, to protect user privacy and data security.
4. **Code generation with LLM**
    The filtered and analyzed prompt is passed to LLM Models, which generate appropriate code suggestions.

## Outbound Flow
5. **Post-processing and response validation**
    - **Code quality**: Responses are checked for common bugs or vulnerabilities, such as cross-site scripting (XSS) or SQL injection, ensuring that the generated code is robust and secure.
    - **Matching public code (optional)**: Optionally, administrators can enable a filter that prevents Copilot from returning suggestions over ~150 characters if they closely resemble existing public code on GitHub. This prevents coincidental matches from being suggested as original content. If any part of the response fails these checks, it is either truncated or discarded.
6. **Suggestion delivery and feedback loop initiation**
    Only responses that pass all filters are delivered to the user. Copilot then initiates a feedback loop based on your actions to achieve the following:
        - Grow its knowledge from accepted suggestions.
        - Learn and improve through modifications and rejections of its suggestions.
7. **Repeat for subsequent prompts**
    The process is repeated as you provide more prompts, with Copilot continuously handling user requests, understanding their intent, and generating code in response.